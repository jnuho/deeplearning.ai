\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Week3}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Neural Network Overview}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Neural Network Representations}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Computing Neural Network Output}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Vectorizing Across Multiple Examples}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Justification for vectorized implementation}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Activation Functions}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Why Non-linear Activation Functions}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Derivatives of Activation Functions.}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}Gradient Descent For Neural Networks}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10}BackPropagation Intuition}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11}Random Initialization}{15}{}\protected@file@percent }
\gdef \@abspage@last{15}
