{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Binary Classification](#bincls)\n",
    "\t- Use logistic regression algorithm for binary classification\n",
    "- [Logistic Regresssion](#logreg)\n",
    "- [Gradient Decent](#gradecent)\n",
    "- [Derivatives](#deriv)\n",
    "- [Computation Graph](#compgraph)\n",
    "- [Logistic Regression Gradient Descent](#logreg-gradecent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n",
    "\n",
    "- Process m training sets w/o loops using matrix\n",
    "- Computation of NN : Forward & Backward propagation steps\n",
    "- 'Logistic Regression' (algorithm for binary classification) to convey above ideas\n",
    "\n",
    "<img src=\"https://i.imgur.com/w1cixJF.png\" style=\"width:550px;height:350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://i.imgur.com/TkGyzQ9.pngK\" style=\"width:550px;height:350px; float: left;\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unroll $i^{th}$ training example into $X^{(i)}$ (three 64 by 64 matrices of RGB)<br>\n",
    "Put entire training sets into $ X \\in$ $R^{n_{x} \\times m}$<br>\n",
    "$X.shape=(n_{x}, m)$<br>\n",
    "$Y.shape=(1, m)$\n",
    "\n",
    "\n",
    "$n_{x} =$ (number of input features) $= 64\\times64\\times3 = 12,288$<br>\n",
    "$m_{train} =$ (number of training data)<br>\n",
    "$m_{test} =$ (number of test data)<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img id=\"logreg\" src=\"https://i.imgur.com/9iAacgB.png\" style=\"width:550px;height:320px;\">\n",
    "\n",
    "In linear regression, $\\hat{y} = w^{T}X+b$. But $\\hat{y}$ should be $0\\leq\\hat{y}\\leq1$<br>\n",
    "In logistic regression,\n",
    "$\\hat{y} = \\sigma({w^T+b})$ using sigmoid function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://i.imgur.com/ae4mzIU.png\" style=\"width:570px;height:330px;\">\n",
    "\n",
    "$\\hat{y}^{(i)}= \\sigma(w^T X^{(i)} + b) = \\sigma(z^{(i)}) = \\frac{1}{1+e^{-z^{(i)}}} where z^{(i)}= w^T X^{(i)} + b$\n",
    "\n",
    "$Given\\ \\{(x^{(1)}, y^{(1)}), ... (x^{(m)}, y^{(m)})\\},\\ want\\ \\hat{y}^{(i)} \\approx y^{(i)}$\n",
    "\n",
    "In logistic regresion implementation objective is to find parameters $w$ and $b$ to make $\\hat{y}$ a good estimate of the chance of Y being equal to 1.\n",
    "\n",
    "\n",
    "In training logistic regression model, find $w$ and $b$ that minimize overall cost function, $J(w,b)$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img id=\"gradecent\" src=\"https://i.imgur.com/m5HTDzl.png\" style=\"width:550px;height:300px; float: left;\">\n",
    "\n",
    "- You've seen the Logistic regression model. Loss function that measures how well you're doing on the single training example. Cost function that measures how well your parameters $w$ and $b$ are doing on your entire training set.\n",
    "- Now let's talk about how you can use the gradient descent algorithm to train, or to learn, the parameters w and b on your training set.\n",
    "\n",
    "- Take iterative steps from initial position to the global optimum\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/2mGFlWu.png\" style=\"width:550px;height:300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"deriv\" src=\"https://i.imgur.com/ffqllqb.png\" style=\"width:550px;height:280px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/HlVVp1t.png\" style=\"width:550px;height:280px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/DrdyBeg.png\" style=\"width:550px;height:280px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"compgraph\" src=\"https://i.imgur.com/zEX9fxz.png\" style=\"width:550px;height:300px;\">\n",
    "\n",
    "One step of backward propagation on a computation graph yields derivative of final output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/XSPppwf.png\" style=\"width:550px;height:300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/fTmw5jJ.png\" style=\"width:550px;height:300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression Gradient descent\n",
    "\n",
    "Want: modify w and b to reduce L-> go backwards propagation to compute derivatives\n",
    "\n",
    "<img id=\"logreg-gradecent\" src=\"https://i.imgur.com/jKcH9jB.png\" style=\"width:550px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://i.imgur.com/Ntnnqey.png\" style=\"width:550px;height:300px; float: left;\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$dz = \\frac{dL}{da} \\cdot \\frac{da}{dz} = \\{-\\frac{y}{a} + \\frac{1-y}{1-a}\\}\\cdot\\{a\\cdot(1-a)\\}$$<br>\n",
    "$$\\frac{da}{dz} = \\frac{d\\sigma(z)}{dz} = \\frac{d}{dz}(\\frac{1}{1+e^{-z}}) = a\\cdot(1-a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://i.imgur.com/AhMybZm.png\" style=\"width:550px;height:250px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$n_x = 2,\\ m = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://i.imgur.com/2pseXrt.png\" style=\"width:550px;height:280px; float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-28dc7766c232>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mlr_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'matplotlib'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'inline'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Downloads\\myworkspace\\deeplearning.ai\\01_Neural_Networks_and_Deep_Learning\\lr_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mh5py\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "# Type the following in 'Python Console' to install dependencies in jupyter\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [data types](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html)\n",
    "\n",
    "# 64x64 with 8-bit integer components\n",
    "print(np.iinfo(np.uint8))\n",
    "\n",
    "for index in range(train_set_x_orig.shape[0]):\n",
    "    cat = train_set_x_orig[index]\n",
    "    assert(np.ndarray(shape=(64, 64, 3), dtype=np.uint8).shape == cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [data types](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html)\n",
    "\n",
    "# 64x64 with 8-bit integer components\n",
    "print(np.iinfo(np.uint8))\n",
    "\n",
    "for index in range(train_set_x_orig.shape[0]):\n",
    "    cat = train_set_x_orig[index]\n",
    "    assert(np.ndarray(shape=(64, 64, 3), dtype=np.uint8).shape == cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [data types](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html)\n",
    "\n",
    "# 64x64 with 8-bit integer components\n",
    "print(np.iinfo(np.uint8))\n",
    "\n",
    "for index in range(train_set_x_orig.shape[0]):\n",
    "    cat = train_set_x_orig[index]\n",
    "    assert(np.ndarray(shape=(64, 64, 3), dtype=np.uint8).shape == cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [data types](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html)\n",
    "\n",
    "# 64x64 with 8-bit integer components\n",
    "print(np.iinfo(np.uint8))\n",
    "\n",
    "for index in range(train_set_x_orig.shape[0]):\n",
    "    cat = train_set_x_orig[index]\n",
    "    assert(np.ndarray(shape=(64, 64, 3), dtype=np.uint8).shape == cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-ac259a959011>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# 64x64 with 8-bit integer components\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miinfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_set_x_orig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# [data types](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html)\n",
    "\n",
    "# 64x64 with 8-bit integer components\n",
    "print(np.iinfo(np.uint8))\n",
    "\n",
    "for index in range(train_set_x_orig.shape[0]):\n",
    "    cat = train_set_x_orig[index]\n",
    "    assert(np.ndarray(shape=(64, 64, 3), dtype=np.uint8).shape == cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-11ae062e",
   "language": "python",
   "display_name": "PyCharm (deeplearning.ai)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}