{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Vectorization](#vect)\n",
    "* [Vectorizing Logistic Regression](#vectlogreg)\n",
    "* [Broadcasting](#broadcasting)\n",
    "* [Python Numpy](#numpy)\n",
    "* [Explanation of Logistic Regression Cost function](#explanation-of-logistic-regression-cost-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"vect\" src=\"https://i.imgur.com/TxXjiYe.png\" style=\"width:650px;height:370px; float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)\n",
    "a = a.reshape(4,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249600.7661425908\n",
      "Vectorized version:16.780853271484375ms\n",
      "249600.76614258674\n",
      "For loop version:362.78390884399414ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"Vectorized version:\" + str(1000*(toc-tic)) + \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"For loop version:\" + str(1000*(toc-tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/dazXdzS.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/TAYpdTB.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/kWcoJQh.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"vectlogreg\" src=\"https://i.imgur.com/H42svVk.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z = [z^{(1)}, ..., z^{(m)}] = [w^{T}x^{(1)}+b, ..., w^{T}x^{(m)}+b] = np.dot(w\\cdot T, x) + b$$\n",
    "\n",
    "$$A = \\sigma(z) = [\\sigma(w^{T}x^{(1)}+b), ..., \\sigma(w^{T}x^{(m)}+b)] = [a^{(1)}, ... , a^{(m)}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Xng06L5.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/SAyvy3n.png\" style=\"width:650px;height:380px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of features in a single image input $= 64 * 64 * 3 = 12288$\n",
    "\n",
    "We assume $ m = m_{train}$ and $n = n_{x}.$<br>\n",
    "For $i=1,2, \\dots , m$\n",
    "$$ x^{(i)} = \\begin{bmatrix}\n",
    "    x^{(i)}_{1} \\\\\n",
    "    x^{(i)}_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    x^{(i)}_{n}\n",
    "\\end{bmatrix}$$ <br>\n",
    "\n",
    "That is\n",
    "$$ X = \\begin{bmatrix}\n",
    "    \\vdots & &\\vdots \\\\\n",
    "    x^{(1)} & \\dots & x^{(m)} \\\\\n",
    "    \\vdots & & \\vdots\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$ A = \\begin{bmatrix}a^{(1)} & \\dots & a^{(m)} \\end{bmatrix} = \n",
    "\\begin{bmatrix} \\sigma (w^Tx^{(1)} + b) & \\dots & \\sigma (w^Tx^{(m)} + b) \\end{bmatrix}\\ where\\ \\hat{y}^{(i)} = a^{(i)}$$ \n",
    "\n",
    "Loss function:\n",
    "$$ L(a^{(i)}, y^{(i)}) = -[y^{(i)}\\log{a^{(i)}} + (1-y^{(i)})\\log{(1-a^{(i)}})]$$\n",
    "\n",
    "\n",
    "\n",
    "Assume $n = 2,\\ m =1$:<br>\n",
    "$$ z^{(i)} = w_1x_1 + w_2x_1 + b$$<br>\n",
    "$$ dz^{(i)} = \\frac{dL}{dz^{(i)}} = \\frac{dL}{da^{(i)}} \\frac{da^{(i)}}{dz^{(i)}}\n",
    " = [-\\frac{y^{(i)}}{a^{(i)}} + \\frac{1-y^{(i)}}{1-a^{(i)}}][a^{(i)}(1-a^{(i)})] = a^{(i)} - y^{(i)} $$<br>\n",
    "\n",
    "$$ dw_1 = \\frac{dL}{dw_{1}} = \\frac{dL}{dz^{(i)}}\\frac{dz^{(i)}}{dw_{1}} = \\frac{dL}{dz^{(i)}}x_{1} $$<br>\n",
    "$$ dw_2 = \\frac{dL}{dw_{2}} = \\frac{dL}{dz^{(i)}}x_{2} $$<br>\n",
    "$$ db = \\frac{dL}{db} = \\frac{dL}{dz^{(i)}}\\frac{dz^{(i)}}{db} = \\frac{dL}{dz^{(i)}} $$<br>\n",
    "\n",
    "Assume for general case with $n,\\ m$<br>\n",
    "$$ z^{(i)} = w^Tx^{(i)} + b = \\begin{bmatrix}w_1 & \\dots & w_n \\end{bmatrix} \\begin{bmatrix}\n",
    "    x^{(i)}_{1} \\\\\n",
    "    x^{(i)}_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    x^{(i)}_{n_x}\n",
    "\\end{bmatrix} + b = w_1x^{(i)}_1 + w_2x^{(i)}_2 + \\dots + w_nx^{(i)}_n + b $$\n",
    "\n",
    "$$ dz^{(i)} = \\frac{dL}{dz^{(i)}} = a^{(i)} - y^{(i)} $$\n",
    "$$ dw_1 = \\frac{dL}{dw_1} = dz^{(i)}x^{(i)}_{1} $$\n",
    "$$ dw_2 = \\frac{dL}{dw_2} = dz^{(i)}x^{(i)}_{2} $$\n",
    "$$\\dots$$\n",
    "$$ dw_n = \\frac{dL}{dw_n} = dz^{(i)}x^{(i)}_{n} $$\n",
    "\n",
    "$ \\frac{dL}{dW}$ can be expressed as \n",
    "$$ \\frac{dL}{dW} = \\begin{bmatrix} dz^{(i)}x^{(i)}_{1} & dz^{(i)}x^{(i)}_{2} & \\dots & dz^{(i)}x^{(i)}_{n} \\end{bmatrix} = \\begin{bmatrix} x^{(i)}_{1} & x^{(i)}_{2} & \\dots & x^{(i)}_{n} \\end{bmatrix} dz^{(i)}\n",
    "= x^{(i)}dz^{(i)}\n",
    "$$\n",
    "\n",
    "$$ \\frac{dL}{db} = \\frac{dL}{dz^{(i)}} = dz^{(i)} $$<br>\n",
    "\n",
    "$$ dZ = \\begin{bmatrix} dz^{(1)} & dz^{(2)} & \\dots & dz^{(m)} \\end{bmatrix} $$\n",
    "\n",
    "$$ J(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} L(a^{(i)},y^{(i)})$$\n",
    "\n",
    "$$ dW = \\frac{dJ}{dW} = \\frac{1}{m}\\sum_{i=1}^{m} \\frac{dL(a^{(i)},y^{(i)})}{dW} \n",
    "= \\frac{1}{m}\\sum_{i=1}^{m}x^{(i)}dz^{(i)} = \\frac{1}{m}[x^{(1)}dz^{(1)} + x^{(2)}dz^{(2)} + \\dots + x^{(m)}dz^{(m)}] \n",
    "= \\frac{1}{m}\\begin{bmatrix}\n",
    "    \\vdots & &\\vdots \\\\\n",
    "    x^{(1)} & \\dots & x^{(m)} \\\\\n",
    "    \\vdots & & \\vdots\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "dz^{(1)} \\\\\n",
    "dz^{(2)} \\\\\n",
    "\\dots \\\\\n",
    "dz^{(m)} \\end{bmatrix}\n",
    "= \\frac{1}{m}X\\cdot(dZ)^T$$\n",
    "\n",
    "$$ db = \\frac{dJ}{db} = \\frac{1}{m}\\sum_{i=1}^{m} \\frac{dL(a^{(i)},y^{(i)})}{db} \n",
    "= \\frac{1}{m}\\sum_{i=1}^{m} dz^{(i)} = \\frac{1}{m}np.sum(dZ)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"broadcasting\" src=\"https://i.imgur.com/yKUl3eP.png\" style=\"width:650px;height:400px; float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.   239.42 152.    76.9 ]\n",
      "[125.42 165.2  236.7 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[56.0, 0.42, 1.0, 68.0],\n",
    "             [1.2,104.0,52.0,8.0],\n",
    "             [1.8,135.0,99.0,0.9]])\n",
    "\n",
    "print(A.sum(axis=0))\n",
    "print(A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.   239.42 152.    76.9 ]\n",
      "[[0.94915254 0.00175424 0.00657895 0.88426528]\n",
      " [0.02033898 0.43438309 0.34210526 0.10403121]\n",
      " [0.03050847 0.56386267 0.65131579 0.01170351]]\n"
     ]
    }
   ],
   "source": [
    "cal = A.sum(axis=0)\n",
    "print(cal)\n",
    "\n",
    "percentage = A/cal.reshape(1,4)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/W3neiIl.png\" style=\"width:650px;height:400px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/6TyoPUd.png\" style=\"width:650px;height:400px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"numpy\" src=\"https://i.imgur.com/ydP5Lq3.png\" style=\"width:620px;height:340px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT USE $$a=np.random.randn(5)$$\n",
    "USE $$a=np.random.randn(5,1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12435934  0.55887327 -0.74688549  0.75457606  2.42248591]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.randn(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "#DO NOT USE rank 1 array(neither row/column vector)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12435934  0.55887327 -0.74688549  0.75457606  2.42248591]\n"
     ]
    }
   ],
   "source": [
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.323465529687509\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(a,a.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25004253]\n",
      " [ 0.78163914]\n",
      " [-0.27280061]\n",
      " [-0.06877438]\n",
      " [-0.84532257]]\n"
     ]
    }
   ],
   "source": [
    "# column vector\n",
    "a = np.random.randn(5,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25004253  0.78163914 -0.27280061 -0.06877438 -0.84532257]]\n"
     ]
    }
   ],
   "source": [
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.56260631  0.97708217 -0.34101236 -0.0859709  -1.05668916]\n",
      " [ 0.97708217  0.61095975 -0.21323164 -0.05375675 -0.66073721]\n",
      " [-0.34101236 -0.21323164  0.07442017  0.01876169  0.23060451]\n",
      " [-0.0859709  -0.05375675  0.01876169  0.00472992  0.05813654]\n",
      " [-1.05668916 -0.66073721  0.23060451  0.05813654  0.71457024]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(a,a.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(a.shape == (5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of Logistic Regression Cost function\n",
    "$$\\hat{y}^{(i)}= \\sigma(w^T X^{(i)} + b) = \\sigma(z^{(i)}) = \\frac{1}{1+e^{-z}},\\ where\\ z^{(i)}= w^T X^{(i)} + b$$\n",
    "\n",
    "$$\\hat{y}= P(y=1|X)$$\n",
    "\n",
    "$$If\\ y=1:\\ P(y|x) = \\hat{y}$$\n",
    "$$If\\ y=0:\\ P(y|x) = 1 - \\hat{y}$$\n",
    "\n",
    "$$P(y|x) = \\hat{y}^{y}\\cdot(1 - \\hat{y})^{(1-y)}$$\n",
    "\n",
    "$$\\log{P(y|x)} = \\log{\\hat{y}^{y}\\cdot(1 - \\hat{y})^{(1-y)}} = y\\cdot\\log{\\hat{y}} + (1 - y)\\cdot\\log(1-\\hat{y}) = -L(\\hat{y}, y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost on m examples\n",
    "find maximum likelyhood estimation; choose parameters to maximize probability\n",
    "$$\\log{p(labels\\ in\\ training\\ set)} = \\log{\\prod_{i=1}^{m}p(y^{(i)}|x^{(i)})} = \\sum_{i=1}^{m}\\log{p(y^{(i)}|x^{(i)})}$$\n",
    "$$ = \\sum_{i=1}^{m}-L(\\hat{y}^{(i)}, y^{(i)})$$\n",
    "\n",
    "minimize cost to maximize the probability\n",
    "$$Cost\\ = J(w,b) = \\frac{1}{m}\\cdot\\sum_{i=1}^{m}-L(\\hat{y}^{(i)}, y^{(i)})$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
